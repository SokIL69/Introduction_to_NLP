{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Введение в обработку естественного языка\n",
    "# Урок 3. Embedding word2vec fasttext"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Задача поиск похожих по эмбеддингам\n",
    "\n",
    "Скачиваем датасет (источник - http://study.mokoron.com/):\n",
    "- положительные - https://www.dropbox.com/s/fnpq3z4bcnoktiv/positive.csv?dl=0,\n",
    "- отрицательные - https://www.dropbox.com/s/r6u59ljhhjdg6j0/negative.csv.\n",
    "\n",
    "или можно через ноутбук\n",
    "\n",
    "!wget https://www.dropbox.com/s/fnpq3z4bcnoktiv/positive.csv<br>\n",
    "!wget https://www.dropbox.com/s/r6u59ljhhjdg6j0/negative.csv\n",
    "\n",
    "что надо сделать\n",
    "1. объединить в одну выборку\n",
    "2. на основе word2vec/fasttext/glove/слоя Embedding реализовать метод поиска ближайших твитов<br>\n",
    "(на вход метода должен приходить запрос (какой-то твит, вопрос) и количество вариантов вывода к примеру 5-ть, \n",
    "ваш метод должен возвращать 5-ть ближайших твитов к этому запросу)\n",
    "3. Проверить насколько хорошо работают подходы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выполнил ___Соковнин ИЛ___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from sklearn.metrics import *\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Сброс ограничений на количество символов в записи\n",
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='darkblue'>Задания:</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='darkblue'>1. Скачать датасет и объединить в одну выборку</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@first_timee хоть я и школота, но поверь, у нас то же самое :D общество профилирующий предмет типа)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Да, все-таки он немного похож на него. Но мой мальчик все равно лучше:D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RT @KatiaCheh: Ну ты идиотка) я испугалась за тебя!!!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RT @digger2912: \"Кто то в углу сидит и погибает от голода, а мы ещё 2 порции взяли, хотя уже и так жрать не хотим\" :DD http://t.co/GqG6iuE2…</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@irina_dyshkant Вот что значит страшилка :D\\nНо блин,посмотрев все части,у тебя создастся ощущение,что авторы курили что-то :D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111918</th>\n",
       "      <td>Но не каждый хочет что то исправлять:( http://t.co/QNODDQzuZ7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111919</th>\n",
       "      <td>скучаю так :-( только @taaannyaaa вправляет мозги, но я все равно скучаю</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111920</th>\n",
       "      <td>Вот и в школу, в говно это идти уже надо(</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111921</th>\n",
       "      <td>RT @_Them__: @LisaBeroud Тауриэль, не грусти :( *обнял*</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111922</th>\n",
       "      <td>Такси везет меня на работу. Раздумываю приплатить, чтобы меня втащили на пятый этаж. Лифта то нет :(</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>226834 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                text\n",
       "0                                                @first_timee хоть я и школота, но поверь, у нас то же самое :D общество профилирующий предмет типа)\n",
       "1                                                                            Да, все-таки он немного похож на него. Но мой мальчик все равно лучше:D\n",
       "2                                                                                              RT @KatiaCheh: Ну ты идиотка) я испугалась за тебя!!!\n",
       "3       RT @digger2912: \"Кто то в углу сидит и погибает от голода, а мы ещё 2 порции взяли, хотя уже и так жрать не хотим\" :DD http://t.co/GqG6iuE2…\n",
       "4                     @irina_dyshkant Вот что значит страшилка :D\\nНо блин,посмотрев все части,у тебя создастся ощущение,что авторы курили что-то :D\n",
       "...                                                                                                                                              ...\n",
       "111918                                                                                 Но не каждый хочет что то исправлять:( http://t.co/QNODDQzuZ7\n",
       "111919                                                                      скучаю так :-( только @taaannyaaa вправляет мозги, но я все равно скучаю\n",
       "111920                                                                                                     Вот и в школу, в говно это идти уже надо(\n",
       "111921                                                                                       RT @_Them__: @LisaBeroud Тауриэль, не грусти :( *обнял*\n",
       "111922                                          Такси везет меня на работу. Раздумываю приплатить, чтобы меня втащили на пятый этаж. Лифта то нет :(\n",
       "\n",
       "[226834 rows x 1 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Как объединить DataFrames в Pandas - merge (), join (), append (), concat () и update ()\n",
    "# https://rukovodstvo.net/posts/id_606/#mergedataframesusingappend\n",
    "# считываем данные и заполняем общий датасет\n",
    "positive = pd.read_csv('./data/positive.csv', sep=';', usecols=[3], names=['text'])\n",
    "negative = pd.read_csv('./data/negative.csv', sep=';', usecols=[3], names=['text'])\n",
    "df = positive.append(negative)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df (226834, 1)\n",
      "positive (114911, 1)\n",
      "negative (111923, 1)\n",
      "(226834, 1) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('df', df.shape)\n",
    "print('positive', positive.shape)\n",
    "print('negative', negative.shape)\n",
    "print(df.shape, '\\n')\n",
    "\n",
    "# print('Row count is:', df.shape[0])\n",
    "# print('Row count is:', len(df.index))\n",
    "# print('Row count is:', len(df.axes[0]), '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 226834 entries, 0 to 111922\n",
      "Data columns (total 1 columns):\n",
      " #   Column  Non-Null Count   Dtype \n",
      "---  ------  --------------   ----- \n",
      " 0   text    226834 non-null  object\n",
      "dtypes: object(1)\n",
      "memory usage: 3.5+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# positive.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# negative.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "text    @Ma_che_rie посмотри #непытайтесьпокинутьомск сегодня в Вавилоне в 18.20. Я там тоже есть :)\n",
       "Name: 114910, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Выбрать конкретную строку и столбец\n",
    "df.iloc[114910, ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "text    RT @bazzzilio: @VRSoloviev :)) Я все еще жив, придурки. Перестаньте путать меня с Нельсоном Манделой. Спасибо. http://t.co/JmOp42vhwb\n",
       "Name: 111922, dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[111922, ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_patern(text, patern, text_repl):\n",
    "    \"\"\" \n",
    "    Заменим патерн на пробелы.\n",
    "    \"\"\"\n",
    "    text = re.sub(patern, text_repl, text) \n",
    "\n",
    "    return  text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 846 ms\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>хоть я и школота, но поверь, у нас то же самое :D общество профилирующий предмет типа)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Да, все-таки он немного похож на него. Но мой мальчик все равно лучше:D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RT : Ну ты идиотка) я испугалась за тебя!!!</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                      text\n",
       "0   хоть я и школота, но поверь, у нас то же самое :D общество профилирующий предмет типа)\n",
       "1                  Да, все-таки он немного похож на него. Но мой мальчик все равно лучше:D\n",
       "2                                              RT : Ну ты идиотка) я испугалась за тебя!!!"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# Удалим @user из всех текстов\n",
    "df['text'] = df['text'].apply(replace_patern, patern =  r'@[\\w]*', text_repl='')\n",
    "# Заменим пунктуацию на пробелы, используя re.sub() и паттерн r'[^\\w\\s]'.\n",
    "# df['text'] = df['text'].apply(replace_patern, patern =  r'[^\\w\\s]')\n",
    "# Заменим спец. символы на пробелы\n",
    "# df['text'] = df['text'].apply(replace_patern, patern =  r'[^a-zA-Z0-9]')\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Векторизация"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1.82 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>хоть я и школота, но поверь, у нас то же самое :D общество профилирующий предмет типа)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Да, все-таки он немного похож на него. Но мой мальчик все равно лучше:D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RT : Ну ты идиотка) я испугалась за тебя!!!</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                      text\n",
       "0   хоть я и школота, но поверь, у нас то же самое :D общество профилирующий предмет типа)\n",
       "1                  Да, все-таки он немного похож на него. Но мой мальчик все равно лучше:D\n",
       "2                                              RT : Ну ты идиотка) я испугалась за тебя!!!"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "df.text = np.vectorize(replace_patern)(text=df.text, patern =  r'@[\\w]*', text_repl='')\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"./text.txt\", header=None, index=False, encoding='utf-8')  # Сохранение без индексации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine_df = pd.read_csv(\"./text.csv\")\n",
    "# combine_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 983 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "text_in = open('text.txt','r', encoding='utf-8')\n",
    "# print(type(text_in))\n",
    "# print(*text_in)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# \n",
    "## <font color='darkblue'>2. На основе word2vec/fasttext/glove/слоя Embedding реализовать метод поиска ближайших твитов</font>\n",
    "(на вход метода должен приходить запрос (какой-то твит, вопрос) и количество вариантов<br>\n",
    "вывода к примеру 5-ть, ваш метод должен возвращать 5-ть ближайших твитов к этому запросу)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Загрузка предобученной модели русского корпуса\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Векторное представление слов https://neerc.ifmo.ru/wiki/index.php?title=Векторное_представление_слов\n",
    "\n",
    "Модели https://rusvectores.org/ru/models/#ruwikiruscorpora_upos_cbow_300_10_2021\n",
    "\n",
    "Embeddings W2V https://colab.research.google.com/drive/11tkidAcwXRr8x3hDIDFd6DisVmHeTqHB?usp=sharing#scrollTo=zm9z6SN3X-rS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "import gensim.downloader as download_api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['fasttext-wiki-news-subwords-300', 'conceptnet-numberbatch-17-06-300', 'word2vec-ruscorpora-300', 'word2vec-google-news-300', 'glove-wiki-gigaword-50', 'glove-wiki-gigaword-100', 'glove-wiki-gigaword-200', 'glove-wiki-gigaword-300', 'glove-twitter-25', 'glove-twitter-50', 'glove-twitter-100', 'glove-twitter-200', '__testing_word2vec-matrix-synopsis'])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# список предобученных моделей\n",
    "download_api.info()['models'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "russian_model = download_api.load('word2vec-ruscorpora-300')  # загрузим предтренированные вектора слов из gensim-data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['весь_DET',\n",
       " 'человек_NOUN',\n",
       " 'мочь_VERB',\n",
       " 'год_NOUN',\n",
       " 'сказать_VERB',\n",
       " 'время_NOUN',\n",
       " 'говорить_VERB',\n",
       " 'становиться_VERB',\n",
       " 'знать_VERB',\n",
       " 'самый_DET']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # Выведем первые 10 слов корпуса.\n",
    "# # В модели \"word2vec-ruscorpora-300\" после слова указывается часть речи: NOUN (существительное), ADJ (прилагательное) и так далее.\n",
    "# # Но существуют также предоубученные модели без разделения слов по частям речи, смотри репозиторий\n",
    "list(russian_model.index_to_key)[:10]\n",
    "# # ['весь_DET', 'человек_NOUN', 'мочь_VERB', 'год_NOUN', 'сказать_VERB', 'время_NOUN', 'говорить_VERB', 'становиться_VERB', 'знать_VERB', 'самый_DET']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('кот_NOUN', 0.7570087909698486),\n",
       " ('котенок_NOUN', 0.7261239290237427),\n",
       " ('собака_NOUN', 0.6963180303573608),\n",
       " ('мяукать_VERB', 0.6411399841308594),\n",
       " ('крыса_NOUN', 0.6355635523796082),\n",
       " ('собачка_NOUN', 0.6092043519020081),\n",
       " ('щенок_NOUN', 0.6028496623039246),\n",
       " ('мышь_NOUN', 0.5975363254547119),\n",
       " ('пес_NOUN', 0.5956044793128967),\n",
       " ('кошечка_NOUN', 0.5920294523239136)]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Поиск наиболее близких по смыслу слов.\n",
    "russian_model.most_similar('кошка_NOUN')\n",
    "#  [('кот_NOUN', 0.7570087909698486), ('котенок_NOUN', 0.7261239290237427), ('собака_NOUN', 0.6963180303573608),\n",
    "#  ('мяукать_VERB', 0.6411399841308594), ('крыса_NOUN', 0.6355636119842529), ('собачка_NOUN', 0.6092042922973633),\n",
    "#  ('щенок_NOUN', 0.6028496026992798), ('мышь_NOUN', 0.5975362062454224), ('пес_NOUN', 0.5956044793128967),\n",
    "#  ('кошечка_NOUN', 0.5920293927192688)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8522827"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Вычисление сходства слов\n",
    "russian_model.similarity('мужчина_NOUN', 'женщина_NOUN')\n",
    "# 0.85228276"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'хлопья_NOUN'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Поиск лишнего слова\n",
    "russian_model.doesnt_match('завтрак_NOUN хлопья_NOUN обед_NOUN ужин_NOUN'.split())\n",
    "# хлопья_NOUN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('королева_NOUN', 0.7313904166221619)]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Аналогия: Женщина + (Король - Мужчина) = Королева\n",
    "russian_model.most_similar(positive=['король_NOUN','женщина_NOUN'], negative=['мужчина_NOUN'], topn=1)\n",
    "# [('королева_NOUN', 0.7313904762268066)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('франция_NOUN', 0.8673799633979797)]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Аналогия: Франция = Париж + (Германия - Берлин)\n",
    "russian_model.most_similar(positive=['париж_NOUN','германия_NOUN'], negative=['берлин_NOUN'], topn=1)\n",
    "# [('франция_NOUN', 0.8673800230026245)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Загрузка предобученной модели glove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "queen: 0.7699\n"
     ]
    }
   ],
   "source": [
    "word_vectors = download_api.load(\"glove-wiki-gigaword-100\")  # загрузим предтренированные вектора слов из gensim-data\n",
    "# выведим слово наиболее близкое к 'woman', 'king' и далекое от 'man'\n",
    "result = word_vectors.most_similar(positive=['woman', 'king'], negative=['man'])\n",
    "print(\"{}: {:.4f}\".format(*result[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cereal\n",
      "summer\n"
     ]
    }
   ],
   "source": [
    "# выведем лишнее слово\n",
    "print(word_vectors.doesnt_match(\"breakfast cereal dinner lunch\".split()))\n",
    "\n",
    "print(word_vectors.doesnt_match(\"black green summer brown\".split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8323494\n",
      "0.5288512\n",
      "0.21199904\n"
     ]
    }
   ],
   "source": [
    "# определим схожесть между словами\n",
    "similarity = word_vectors.similarity('woman', 'man')\n",
    "print(similarity)\n",
    "\n",
    "similarity = word_vectors.similarity('human', 'man')\n",
    "print(similarity)\n",
    "\n",
    "similarity = word_vectors.similarity('bee', 'man')\n",
    "print(similarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('woman', 0.832349419593811), ('boy', 0.7914870977401733), ('one', 0.7788748741149902)]\n",
      "[('dog', 0.8798074126243591), ('rabbit', 0.7424427270889282), ('cats', 0.732300341129303)]\n",
      "[('tongue', 0.7366125583648682), ('mouths', 0.687748908996582), ('ear', 0.6811771392822266)]\n"
     ]
    }
   ],
   "source": [
    "# найдем top-3 самых близких слов\n",
    "result = word_vectors.similar_by_word(\"man\", topn=3)\n",
    "print(result)\n",
    "\n",
    "result = word_vectors.similar_by_word(\"cat\", topn=3)\n",
    "print(result)\n",
    "\n",
    "result = word_vectors.similar_by_word(\"mouth\", topn=3)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Обучение модели word2vec и fastText на текстовом корпусе"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.word2vec import Word2Vec\n",
    "from gensim.models.fasttext import FastText\n",
    "import gensim.downloader as download_api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "Word2Vec?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<text8.Dataset at 0x2351c47d30>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Скачаем небольшой текстовый корпус (32 Мб) и откроем его как итерируемый набор предложений: iterable(list(string))\n",
    "# В этом текстовом корпусе часть речи для слов не указывается\n",
    "corpus = download_api.load('text8')\n",
    "corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Обучим модели word2vec и fastText\n",
    "word2vec_model = Word2Vec(corpus, vector_size=100, workers=4)\n",
    "fastText_model = FastText(corpus, vector_size=100, workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('driver', 0.7955479621887207),\n",
       " ('taxi', 0.7173714637756348),\n",
       " ('cars', 0.7153368592262268)]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2vec_model.wv.most_similar('car')[:3]\n",
    "# [('driver', 0.8033335208892822), ('motorcycle', 0.7368553876876831), ('cars', 0.7001584768295288)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('lcar', 0.8797328472137451),\n",
       " ('boxcar', 0.8650722503662109),\n",
       " ('ccar', 0.8415129780769348)]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fastText_model.wv.most_similar('car')[:3]\n",
    "# [('lcar', 0.8733218908309937), ('boxcar', 0.8559106588363647), ('ccar', 0.8268736004829407)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "from tqdm import tqdm_notebook\n",
    "from tqdm import notebook\n",
    "from pymorphy2 import MorphAnalyzer\n",
    "from stop_words import get_stop_words\n",
    "import annoy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fed2d898e2334d5c891a0fab91301b70",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "assert True\n",
    "\n",
    "#Small preprocess of the answers\n",
    "\n",
    "question = None\n",
    "written = False\n",
    "\n",
    "with open(\"prepared_text.txt\", \"w\") as fout:\n",
    "    with open(\"text.txt\", \"r\", encoding='utf-8') as fin:\n",
    "        for line in notebook.tqdm(fin):\n",
    "            if line.startswith(\"---\"):\n",
    "                written = False\n",
    "                continue\n",
    "            if not written and question is not None:\n",
    "                fout.write(question.replace(\"\\t\", \" \").strip() + \"\\t\" + line.replace(\"\\t\", \" \"))\n",
    "                written = True\n",
    "                question = None\n",
    "                continue\n",
    "            if not written:\n",
    "                question = line.strip()\n",
    "                continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "\n",
    "# prepared_text = open('prepared_text.txt','r')\n",
    "# print(*prepared_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_txt(line):\n",
    "    spls = \"\".join(i for i in line.strip() if i not in exclude).split()\n",
    "    spls = [morpher.parse(i.lower())[0].normal_form for i in spls]\n",
    "    spls = [i for i in spls if i not in sw and i != \"\"]\n",
    "    return spls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c55d932326964c05bc535b8319ce526a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "assert True\n",
    "\n",
    "# Preprocess for models fitting\n",
    "\n",
    "sentences = []\n",
    "\n",
    "morpher = MorphAnalyzer()\n",
    "sw = set(get_stop_words(\"ru\"))\n",
    "exclude = set(string.punctuation)\n",
    "c = 0\n",
    "\n",
    "with open(\"text.txt\", \"r\", encoding='utf-8') as fin:\n",
    "    for line in notebook.tqdm(fin):\n",
    "        spls = preprocess_txt(line)\n",
    "        sentences.append(spls)\n",
    "        c += 1\n",
    "        if c > 100000:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = [i for i in sentences if len(i) > 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['школотый',\n",
       " 'поверь',\n",
       " 'самый',\n",
       " 'd',\n",
       " 'общество',\n",
       " 'профилировать',\n",
       " 'предмет',\n",
       " 'тип']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='darkblue'>2.1 На основе word2vec реализовать метод поиска ближайших твитов</font><br>\n",
    "<font color='darkblue'>2.2 На основе fasttext реализовать метод поиска ближайших твитов</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelW2V = Word2Vec(sentences=sentences, vector_size=300, window=5, min_count=4)\n",
    "# indexW2V = build_index(modelW2V)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelFT = FastText(sentences=sentences, vector_size=300, min_count=4, window=5, workers=8)\n",
    "# indexFT = build_index(modelFT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-41-e490301d4d3e>:8: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  for line in tqdm_notebook(f):\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "465afadb865c4152b46b9937133aeea3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_index = annoy.AnnoyIndex(300 ,'angular')\n",
    "ft_index = annoy.AnnoyIndex(300 ,'angular')\n",
    "\n",
    "index_map = {}\n",
    "counter = 0\n",
    "\n",
    "with open(\"prepared_text.txt\", \"r\") as f:\n",
    "    for line in tqdm_notebook(f):\n",
    "        n_w2v = 0\n",
    "        n_ft = 0\n",
    "        spls = line.split(\"\\t\")\n",
    "        index_map[counter] = spls[1]\n",
    "        question = preprocess_txt(spls[0])\n",
    "        \n",
    "        vector_w2v = np.zeros(300)\n",
    "        vector_ft = np.zeros(300)\n",
    "        for word in question:\n",
    "            if word in modelW2V.wv:\n",
    "                vector_w2v += modelW2V.wv[word]\n",
    "                n_w2v += 1\n",
    "            if word in modelFT.wv:\n",
    "                vector_ft += modelFT.wv[word]\n",
    "                n_ft += 1\n",
    "        if n_w2v > 0:\n",
    "            vector_w2v = vector_w2v / n_w2v\n",
    "        if n_ft > 0:\n",
    "            vector_ft = vector_ft / n_ft\n",
    "        w2v_index.add_item(counter, vector_w2v)\n",
    "        ft_index.add_item(counter, vector_ft)\n",
    "            \n",
    "        counter += 1\n",
    "        \n",
    "        if counter > 100000:\n",
    "            break\n",
    "\n",
    "w2v_index.build(10)\n",
    "ft_index.build(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_response(question, index, model, index_map):\n",
    "    question = preprocess_txt(question)\n",
    "    vector = np.zeros(300)\n",
    "    norm = 0\n",
    "    for word in question:\n",
    "        if word in model.wv:\n",
    "            vector += model.wv[word]\n",
    "            norm += 1\n",
    "    if norm > 0:\n",
    "        vector = vector / norm\n",
    "    answers = index.get_nns_by_vector(vector, 5, )\n",
    "    return [index_map[i] for i in answers]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEXT = \"хоть я и школота, но поверь, у нас то же самое общество профилирующий предмет типа\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\"Да, все-таки он немного похож на него. Но мой мальчик все равно лучше:D\"\\n',\n",
       " '\"с утра романтик, засевший глубоко среди извилин мозга, получил суровым кирпичом действительности по голове) и вас с добры\"\\n',\n",
       " '\"Надеялась, что я добавлю ее в друзья,лохушка :D http://t.co/36k6ADyASA\"\\n',\n",
       " '\"Кто круче - 1,2,3,4 ?) #Suri http://t.co/jZ0INfN4tx\"\\n',\n",
       " '\"И вот я сижу .. А он передо мной ..в трусах , а я засыпаю :D\"\\n']"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_response(TEXT, w2v_index, modelW2V, index_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\"Да, все-таки он немного похож на него. Но мой мальчик все равно лучше:D\"\\n',\n",
       " '\"Кто круче - 1,2,3,4 ?) #Suri http://t.co/jZ0INfN4tx\"\\n',\n",
       " '\"И вот я сижу .. А он передо мной ..в трусах , а я засыпаю :D\"\\n',\n",
       " '\"время двенадцати нету, а я уже дома:)\\n',\n",
       " '\"с утра романтик, засевший глубоко среди извилин мозга, получил суровым кирпичом действительности по голове) и вас с добры\"\\n']"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_response(TEXT, ft_index, modelFT, index_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Вывод__\n",
    "\n",
    "- Сравнивались два метода word2vec и fasttext.\n",
    "- Первые ответы на вопрос адекватны как для word2vec и fasttext\n",
    "- Возможно FastText работает немного лучше."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8 (causalml)",
   "language": "python",
   "name": "causalml-py38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
